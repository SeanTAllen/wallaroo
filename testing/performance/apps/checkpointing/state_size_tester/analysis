#!/usr/bin/env python3

import argparse
import json
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

import file_parser


parser = argparse.ArgumentParser("State Size Test Analysis")
parser.add_argument("-o", "--output-prefix", type=str, dest='prefix',
                    help="The path prefix for saving the post-processed data.")

# Use groups for mutually exclusive features
mex = parser.add_mutually_exclusive_group(required=True)

mex.add_argument("-d", "--application-data", type=str,
                    help="The path to the application output file.")
mex.add_argument("-p", "--processed-data", type=str,
                    help="The path to the processed data file.")
parser.add_argument("-c", "--checkpoints", type=str, default=None,
                    help="The path to the checkpoints stats file.")


args = parser.parse_args()

paths = {'post-processed': args.prefix + '_processed.txt',
         'png': args.prefix + '_performance.png',
         'svg': args.prefix + '_performance.svg',
         'stats': args.prefix + '_stats.txt'}

if args.application_data:
    perf = file_parser.load_output_file(args.application_data)
    if args.checkpoints:
        checkpoints = file_parser.load_checkpoints_file(args.checkpoints)
        # assume only one worker for now
        checkpoints = checkpoints.popitem()[1]
    else:
        checkpoints = {}


    # Use perf data for the time boundaries
    min_ts = min(perf.keys())
    # create a panads dataframe
    data = {}
    for k in list(perf.keys()):
        key = k - min_ts
        data[key] = perf.pop(k)
        data[key].update(checkpoints.get(k, {}))
        pct = data[key].pop('percentiles')
        for p, v in sorted(pct, key=lambda x: x[0]):
            data[key]['p{}'.format(p)] = v

    df = pd.DataFrame.from_dict(data, orient='index')

    with open(paths['post-processed'], 'wt') as f:
        df.to_json(f)
        print("Post-processed data written to {!r}".format(paths['post-processed']))

elif args.processed_data:
    print("Loading processed data from {!r}".format(args.processed_data))
    with open(args.processed_data, 'rt') as f:
        d = json.loads(f.read())
        for col in d:
            for k in list(d[col].keys()):
                d[col][int(k)] = d[col].pop(k)
        df = pd.DataFrame.from_dict(d)

print(df[['count', 'size', 'id', 'p50', 'p95', 'p99', 'p99.9', 'p99.99', 'p100']])
# Get stats
stats = df[['count', 'p50', 'p95', 'p99', 'p99.9', 'p99.99', 'p100']].describe()
# print stats
print(stats)
# save stats
with open(paths['stats'], 'wt') as f:
    stats.to_json(f)
print("Stats data written to {!r}".format(paths['stats']))

fig, ax1 = plt.subplots()
# First axis: latency vs. time
ax1.set_xlabel('Time (s)')
ax1.set_ylabel('Latency (ms)')
df.plot(y='p50', ax=ax1)
df.plot(y='p95', ax=ax1)
df.plot(y='p99', ax=ax1)
df.plot(y='p99.9', ax=ax1)
df.plot(y='p99.99', ax=ax1)
df.plot(y='p100', ax=ax1)

# Second axis: throughput vs. time (using same x axis for time)
ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
ax2.set_ylabel('Throughput')  # we already handled the x-label with ax1
df.plot(y='count', ax=ax2, linewidth=3.5)

fig.tight_layout()  # otherwise the right y-label is slightly clipped

plt.savefig(paths['png'], format='png')
print("Figure saved to {!r}".format(paths['png']))
